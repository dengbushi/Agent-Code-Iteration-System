# ä»£ç æ–‡æ¡£ - å‡½æ•°ä¸ç±»åŠŸèƒ½è¯´æ˜

æœ¬æ–‡æ¡£æŒ‰åŠŸèƒ½åˆ†ç±»è¯¦ç»†è¯´æ˜é¡¹ç›®ä¸­æ¯ä¸ªå‡½æ•°å’Œç±»çš„ä½œç”¨ã€‚

## ğŸ¯ æ ¸å¿ƒä»£ç†ç³»ç»Ÿ

### Agentç±» (`agent.py`)
**ä¸»è¦èŒè´£**: AIä»£ç†çš„æ ¸å¿ƒå†³ç­–å¼•æ“ï¼Œè´Ÿè´£æ•´ä¸ªä»£ç ç”Ÿæˆå’Œä¼˜åŒ–æµç¨‹çš„æ§åˆ¶ã€‚

#### æ ¸å¿ƒæ–¹æ³•

**`__init__(cfg, journal, llm)`**
- åˆå§‹åŒ–ä»£ç†ï¼Œè®¾ç½®é…ç½®ã€çŠ¶æ€ç®¡ç†å™¨å’ŒLLMå®¢æˆ·ç«¯

**`step(exec_callback)`** ğŸš€
- **æ ¸å¿ƒæ‰§è¡Œæ–¹æ³•**ï¼šä»£ç†çš„å•æ­¥æ‰§è¡Œé€»è¾‘
- æ ¹æ®æœç´¢ç­–ç•¥é€‰æ‹©ä¸‹ä¸€ä¸ªæ“ä½œï¼ˆç”Ÿæˆè‰ç¨¿/è°ƒè¯•/æ”¹è¿›ï¼‰
- æ‰§è¡Œä»£ç å¹¶è§£æç»“æœï¼Œæ›´æ–°çŠ¶æ€

```python
def step(self, exec_callback: ExecCallbackType):
    if not self.journal.nodes or self.data_preview is None:
        self.update_data_preview()
    parent_node = self.search_policy()
    if parent_node is None:
        result_node = self._draft()
    elif parent_node.is_buggy:
        result_node = self._debug(parent_node)
    else:
        result_node = self._improve(parent_node)

    self.parse_exec_result(node=result_node, exec_result=exec_callback(result_node.code, True))
    self.journal.append(result_node)
```

**`search_policy()`** ğŸ§ 
- **æ™ºèƒ½æœç´¢ç­–ç•¥**ï¼šå†³å®šä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œä»€ä¹ˆæ“ä½œ
- åŸºäºæ¦‚ç‡é€‰æ‹©è°ƒè¯•æœ‰é—®é¢˜çš„èŠ‚ç‚¹æˆ–æ”¹è¿›æœ€ä½³èŠ‚ç‚¹
- å®ç°æ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡

```python
def search_policy(self) -> Node | None:
    search_cfg = self.cfg.agent.search

    if len(self.journal.draft_nodes) < search_cfg.num_drafts:
        return None

    if random.random() < search_cfg.debug_prob:
        debuggable_nodes = [n for n in self.journal.buggy_nodes if n.is_leaf]
        if debuggable_nodes:
            return random.choice(debuggable_nodes)

    good_nodes = self.journal.good_nodes
    if not good_nodes:
        return None
    return self.journal.get_best_node()
```

#### ä»£ç ç”Ÿæˆæ–¹æ³•

**`_draft()`**
- ç”Ÿæˆåˆå§‹è§£å†³æ–¹æ¡ˆè‰ç¨¿
- åŸºäºä»»åŠ¡æè¿°å’Œæ•°æ®é¢„è§ˆåˆ›å»ºç¬¬ä¸€ç‰ˆä»£ç 

```python
def _draft(self) -> Node:
    system_prompt = "You are an AI agent."
    user_prompt = [
        "You have to come up with a solution for machine learning task and then implement this solution in Python.",
        f"The task is to {str(self.cfg.task_goal)} ",
        f'All the provided input data is stored in "{self.cfg.data_dir}" directory.',
        '**IMPORTANT**: When loading data, you MUST use the provided path variable `data_dir` or the relative path "./dataset" to access the data files.',
        f"{str(self.data_preview)}",
        'You have to save the predictions result on testing set in "/content/submission.csv".',
        'Note that the testing file DOES NOT have the target column.'
    ]
    system_message = system_prompt
    user_message = "\n".join(user_prompt)
    plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)
    return Node(plan=plan, code=code)
```

**`_debug(parent_node)`**
- è°ƒè¯•æœ‰é—®é¢˜çš„ä»£ç 
- åŸºäºé”™è¯¯ä¿¡æ¯å’Œæ‰§è¡Œè¾“å‡ºä¿®å¤ä»£ç 

```python
def _debug(self, parent_node: Node) -> Node:
    system_prompt = "You are an AI agent."
    user_prompt = [
        f"Task description: {str(self.cfg.task_goal)}\n\n",
        f"Previous (buggy) implementation: {str(wrap_code(parent_node.code))}\n\n",
        f"Execution output: {str(wrap_code(parent_node.term_out, lang=''))}\n\n",
        str(self.data_preview)
    ]
    system_message = system_prompt
    user_message = " ".join(user_prompt)
    plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)
    return Node(plan=plan, code=code, parent=parent_node)
```

**`_improve(parent_node)`**
- æ”¹è¿›ç°æœ‰çš„è‰¯å¥½è§£å†³æ–¹æ¡ˆ
- åŸºäºå†å²è®°å½•å’Œå½“å‰æœ€ä½³æ–¹æ¡ˆè¿›è¡Œä¼˜åŒ–

```python
def _improve(self, parent_node: Node) -> Node:
    system_prompt = "You are an AI assistant."
    user_prompt = [
        f"Task description: {str(self.cfg.task_goal)} "
        f"Memory: {str(self.journal.generate_summary())} "
        f"Previous solution: Code: {str(wrap_code(parent_node.code))} "
    ]
    system_message = system_prompt
    user_message = " ".join(user_prompt)
    plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)
    return Node(plan=plan, code=code, parent=parent_node)
```

#### è¾…åŠ©æ–¹æ³•

**`plan_and_code_query(system_message, user_message)`**
- ä¸LLMäº¤äº’ç”Ÿæˆè®¡åˆ’å’Œä»£ç 
- å¤„ç†é‡è¯•é€»è¾‘å’Œä»£ç æå–

```python
def plan_and_code_query(self, system_message, user_message, retries=3) -> tuple[str, str]:
    completion_text = None
    for _ in range(retries):
        response = self.llm.generate_response(
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message},
            ]
        )
        print("--- Start of LLM Response ---")
        print(response)
        print("--- End of LLM Response ---")
        completion_text = response
        code = extract_code(completion_text)
        nl_text = extract_text_up_to_code(completion_text)
        if code:
            return nl_text, code
        print("Plan + code extraction failed, retrying...")
    print("Final plan + code extraction attempt failed, giving up...")
    return "", completion_text
```

**`parse_exec_result(node, exec_result)`**
- è§£æä»£ç æ‰§è¡Œç»“æœ
- ä½¿ç”¨LLMè¯„ä¼°ä»£ç è´¨é‡å’Œæ€§èƒ½æŒ‡æ ‡

```python
def parse_exec_result(self, node: Node, exec_result: ExecutionResult):
    node.absorb_exec_result(exec_result)
    system_prompt = "You are an AI assistant that analyzes code execution results."
    user_prompt = f"""
        Analyze the following code, its execution output, and determine if it's buggy.
        The task is: {self.cfg.task_goal}

        The code implementation is:
        {wrap_code(node.code)}

        The execution output is:
        {wrap_code(node.term_out, lang="")}

        Based on the analysis, provide your evaluation in the following JSON format.
        Do not include any other text outside of the JSON object.

        JSON schema:
        {{
            "is_buggy": <true if the code has bugs or failed, otherwise false>,
            "metric": <the calculated Mean Squared Error (MSE) as a float, or null if not available>,
            "summary": "<a brief summary of the execution results and feedback for improvement>"
        }}
    """

    response = self.llm.generate_response(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    )

    try:
        extracted_json = extract_jsons(response)
        if not extracted_json:
            raise ValueError("No JSON object found in the LLM response.")
        evaluation = Evaluation.model_validate(extracted_json[0])
        node.analysis = evaluation.summary
        node.metric = evaluation.metric
        node.is_buggy = (
            evaluation.is_buggy
            or node.exc_type is not None
            or evaluation.metric is None
        )
    except Exception as e:
        print(f"Failed to parse LLM evaluation response: {e}")
        print(f"Raw response: {response}")
        node.analysis = f"Error during evaluation: {e}"
        node.is_buggy = True
        node.metric = None
```

**`update_data_preview()`**
- æ›´æ–°æ•°æ®é¢„è§ˆä¿¡æ¯ï¼Œä¸ºä»£ç ç”Ÿæˆæä¾›ä¸Šä¸‹æ–‡

```python
def update_data_preview(self):
    self.data_preview = data_preview_generate(self.cfg.data_dir)
```

### Evaluationç±» (`agent.py`)
**æ•°æ®æ¨¡å‹**: ä»£ç æ‰§è¡Œç»“æœçš„è¯„ä¼°ç»“æ„

```python
class Evaluation(BaseModel):
    is_buggy: bool = Field(...)
    metric: float | None = Field(...)
    summary: str = Field(...)
```

- `is_buggy`: ä»£ç æ˜¯å¦æœ‰é”™è¯¯
- `metric`: æ€§èƒ½æŒ‡æ ‡ï¼ˆMSEï¼‰
- `summary`: æ‰§è¡Œç»“æœæ‘˜è¦

## ğŸ“Š çŠ¶æ€ç®¡ç†ç³»ç»Ÿ

### Nodeç±» (`models.py`)
**ä¸»è¦èŒè´£**: è¡¨ç¤ºè§£å†³æ–¹æ¡ˆæ ‘ä¸­çš„å•ä¸ªèŠ‚ç‚¹ï¼ŒåŒ…å«å®Œæ•´çš„è§£å†³æ–¹æ¡ˆä¿¡æ¯ã€‚

#### æ ¸å¿ƒå±æ€§
- `code`: è§£å†³æ–¹æ¡ˆçš„Pythonä»£ç 
- `plan`: è‡ªç„¶è¯­è¨€æè¿°çš„è§£å†³è®¡åˆ’
- `parent/children`: æ ‘çŠ¶ç»“æ„çš„çˆ¶å­å…³ç³»
- `step`: åœ¨æ•´ä¸ªæœç´¢è¿‡ç¨‹ä¸­çš„æ­¥éª¤ç¼–å·

#### æ‰§è¡Œä¿¡æ¯
- `_term_out`: ä»£ç æ‰§è¡Œçš„è¾“å‡ºä¿¡æ¯
- `exec_time`: ä»£ç æ‰§è¡Œæ—¶é—´
- `exc_type/exc_info/exc_stack`: å¼‚å¸¸ä¿¡æ¯

#### è¯„ä¼°ä¿¡æ¯
- `analysis`: LLMå¯¹æ‰§è¡Œç»“æœçš„åˆ†æ
- `metric`: æ€§èƒ½æŒ‡æ ‡ï¼ˆMSEå€¼ï¼‰
- `is_buggy`: æ˜¯å¦å­˜åœ¨é”™è¯¯

#### é‡è¦æ–¹æ³•

**`absorb_exec_result(exec_result)`**
- å¸æ”¶ä»£ç æ‰§è¡Œç»“æœï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€

```python
def absorb_exec_result(self, exec_result: ExecutionResult):
    self._term_out = exec_result.term_out
    self.exec_time = exec_result.exec_time
    self.exc_type = exec_result.exc_type
    self.exc_info = exec_result.exc_info
    self.exc_stack = exec_result.exc_stack
```

**`stage_name`** (å±æ€§)
- è¿”å›èŠ‚ç‚¹é˜¶æ®µï¼š`draft`ï¼ˆè‰ç¨¿ï¼‰ã€`debug`ï¼ˆè°ƒè¯•ï¼‰ã€`improve`ï¼ˆæ”¹è¿›ï¼‰

```python
@property
def stage_name(self) -> Literal["draft", "debug", "improve"]:
    if self.parent is None:
        return "draft"
    return "debug" if self.parent.is_buggy else "improve"
```

**`is_leaf`** (å±æ€§)
- åˆ¤æ–­æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹ï¼ˆæ— å­èŠ‚ç‚¹ï¼‰

```python
@property
def is_leaf(self) -> bool:
    return not self.children
```

**`debug_depth`** (å±æ€§)
- è®¡ç®—è°ƒè¯•æ·±åº¦ï¼ˆè¿ç»­è°ƒè¯•çš„æ¬¡æ•°ï¼‰

```python
@property
def debug_depth(self) -> int:
    if self.stage_name != "debug":
        return 0
    return self.parent.debug_depth + 1  # type: ignore
```

### Journalç±» (`models.py`)
**ä¸»è¦èŒè´£**: ç®¡ç†æ•´ä¸ªè§£å†³æ–¹æ¡ˆæœç´¢è¿‡ç¨‹çš„çŠ¶æ€å’Œå†å²è®°å½•ã€‚

#### æ ¸å¿ƒæ–¹æ³•

**`append(node)`**
- æ·»åŠ æ–°èŠ‚ç‚¹åˆ°æœç´¢å†å²
- è‡ªåŠ¨è®¾ç½®æ­¥éª¤ç¼–å·

```python
def append(self, node: Node) -> None:
    node.step = len(self.nodes)
    self.nodes.append(node)
```

**`get_best_node(only_good=True)`** ğŸ†
- è·å–æ€§èƒ½æœ€ä½³çš„èŠ‚ç‚¹
- å¯é€‰æ‹©åªè€ƒè™‘æ— é”™è¯¯çš„èŠ‚ç‚¹

```python
def get_best_node(self, only_good=True) -> Optional[Node]:
    if only_good:
        nodes = self.good_nodes
        if not nodes:
            return None
    else:
        nodes = self.nodes
    return min(nodes, key=lambda n: n.metric)
```

#### èŠ‚ç‚¹åˆ†ç±»å±æ€§

**`draft_nodes`** (å±æ€§)
- è¿”å›æ‰€æœ‰è‰ç¨¿èŠ‚ç‚¹ï¼ˆæ— çˆ¶èŠ‚ç‚¹çš„æ ¹èŠ‚ç‚¹ï¼‰

```python
@property
def draft_nodes(self) -> list[Node]:
    return [n for n in self.nodes if n.parent is None]
```

**`buggy_nodes`** (å±æ€§)
- è¿”å›æ‰€æœ‰æœ‰é”™è¯¯çš„èŠ‚ç‚¹

```python
@property
def buggy_nodes(self) -> list[Node]:
    return [n for n in self.nodes if n.is_buggy]
```

**`good_nodes`** (å±æ€§)
- è¿”å›æ‰€æœ‰æ— é”™è¯¯çš„èŠ‚ç‚¹

```python
@property
def good_nodes(self) -> list[Node]:
    return [n for n in self.nodes if not n.is_buggy]
```

#### åˆ†ææ–¹æ³•

**`generate_summary(include_code=False)`**
- ç”Ÿæˆæœç´¢è¿‡ç¨‹çš„æ‘˜è¦æŠ¥å‘Š
- åŒ…å«è®¾è®¡æ€è·¯ã€ç»“æœåˆ†æå’Œæ€§èƒ½æŒ‡æ ‡

```python
def generate_summary(self, include_code: bool = False) -> str:
    summary = []
    for n in self.good_nodes:
        summary_part = f"Design: {n.plan}\n"
        if include_code:
            summary_part += f"Code: {n.code}\n"
        summary_part += f"Results: {n.analysis}\n"
        summary_part += f"Validation Metric (Mean Squared Error): {n.metric}\n"
        summary.append(summary_part)
    return "\n-------------------------------\n".join(summary)
```

**`get_metric_history()`**
- è·å–æ‰€æœ‰èŠ‚ç‚¹çš„æ€§èƒ½æŒ‡æ ‡å†å²

```python
def get_metric_history(self) -> list[float]:
    return [n.metric for n in self.nodes]
```

## âš¡ ä»£ç æ‰§è¡Œå¼•æ“

### Interpreterç±» (`interpreter_module.py`)
**ä¸»è¦èŒè´£**: æä¾›å®‰å…¨çš„ã€éš”ç¦»çš„Pythonä»£ç æ‰§è¡Œç¯å¢ƒã€‚

#### æ ¸å¿ƒæ–¹æ³•

**`run(code, reset_session=True)`** ğŸ”¥
- **ä¸»è¦æ‰§è¡Œæ–¹æ³•**ï¼šåœ¨éš”ç¦»è¿›ç¨‹ä¸­æ‰§è¡ŒPythonä»£ç 
- æ”¯æŒä¼šè¯é‡ç½®å’ŒæŒç»­ä¼šè¯
- è¿”å›å®Œæ•´çš„æ‰§è¡Œç»“æœ

```python
def run(self, code: str, reset_session=True) -> ExecutionResult:
    if reset_session:
        if self.process is not None:
            self.cleanup_session()
        self.create_process()
    else:
        assert self.process is not None

    assert self.process.is_alive()
    self.code_inq.put(code)

    try:
        state = self.event_outq.get(timeout=30)
    except queue.Empty:
        msg = "REPL child process failed to start execution"
        while not self.result_outq.empty():
            break
        raise RuntimeError(msg) from None
    assert state[0] == "state:ready", state
    start_time = time.time()

    child_in_overtime = False
    while True:
        try:
            state = self.event_outq.get(timeout=1)
            assert state[0] == "state:finished", state
            exec_time = time.time() - start_time
            break
        except queue.Empty:
            if time.time() - start_time > self.timeout:
                if not child_in_overtime:
                    child_in_overtime = True
                    self.process.terminate()
                else:
                    self.process.kill()
                    break
            continue

    # æ”¶é›†è¾“å‡ºç»“æœ
    term_out = []
    while not self.result_outq.empty():
        try:
            msg = self.result_outq.get_nowait()
            if msg == "<|EOF|>":
                break
            term_out.append(msg)
        except queue.Empty:
            break

    return ExecutionResult(
        term_out=term_out,
        exec_time=exec_time,
        exc_type=state[1] if len(state) > 1 else None,
        exc_info=state[2] if len(state) > 2 else None,
        exc_stack=state[3] if len(state) > 3 else None,
    )
```

**`create_process()`**
- åˆ›å»ºæ–°çš„å­è¿›ç¨‹ç”¨äºä»£ç æ‰§è¡Œ
- è®¾ç½®è¿›ç¨‹é—´é€šä¿¡é˜Ÿåˆ—

```python
def create_process(self) -> None:
    ctx = mp.get_context("spawn")
    self.code_inq, self.result_outq, self.event_outq = ctx.Queue(), ctx.Queue(), ctx.Queue()
    self.process = ctx.Process(target=self._run_session, args=(self.code_inq, self.result_outq, self.event_outq))
    self.process.daemon = True
    self.process.start()
```

**`cleanup_session()`**
- æ¸…ç†æ‰§è¡Œè¿›ç¨‹ï¼Œé‡Šæ”¾èµ„æº
- å¤„ç†è¿›ç¨‹ç»ˆæ­¢å’Œå¼ºåˆ¶æ€æ­»

```python
def cleanup_session(self):
    if self.process is None:
        return
    try:
        self.process.terminate()
        self.process.join(timeout=0.5)
        if self.process.exitcode is None:
            self.process.kill()
            self.process.join(timeout=0.5)
            if self.process.exitcode is None:
                os.kill(self.process.pid, signal.SIGKILL)
    except Exception as e:
        print(f"Error during process cleanup: {e}")
    finally:
        if self.process is not None:
            self.process.close()
            self.process = None
```

#### å†…éƒ¨æ–¹æ³•

**`_run_session(code_inq, result_outq, event_outq)`**
- å­è¿›ç¨‹ä¸­çš„ä¸»æ‰§è¡Œå¾ªç¯
- å¤„ç†ä»£ç ç¼–è¯‘å’Œæ‰§è¡Œ
- æ•è·å¼‚å¸¸å’Œè¾“å‡º

**`child_proc_setup(result_outq)`**
- å­è¿›ç¨‹åˆå§‹åŒ–è®¾ç½®
- é‡å®šå‘æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡º

### ExecutionResultç±» (`interpreter_module.py`)
**æ•°æ®æ¨¡å‹**: ä»£ç æ‰§è¡Œç»“æœçš„å®Œæ•´ä¿¡æ¯
- `term_out`: ç»ˆç«¯è¾“å‡ºä¿¡æ¯
- `exec_time`: æ‰§è¡Œæ—¶é—´
- `exc_type`: å¼‚å¸¸ç±»å‹
- `exc_info`: å¼‚å¸¸è¯¦ç»†ä¿¡æ¯
- `exc_stack`: å¼‚å¸¸å †æ ˆ

### RedirectQueueç±» (`interpreter_module.py`)
**è¾…åŠ©ç±»**: å°†æ ‡å‡†è¾“å‡ºé‡å®šå‘åˆ°é˜Ÿåˆ—
- `write(msg)`: å†™å…¥æ¶ˆæ¯åˆ°é˜Ÿåˆ—
- `flush()`: åˆ·æ–°ç¼“å†²åŒºï¼ˆç©ºå®ç°ï¼‰

## ğŸ¤– LLMäº¤äº’ç³»ç»Ÿ

### LLMClientç±» (`llm_client.py`)
**ä¸»è¦èŒè´£**: å°è£…ä¸å¤§è¯­è¨€æ¨¡å‹çš„äº¤äº’æ¥å£ã€‚

**`__init__(api_key, base_url)`**
- åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯è¿æ¥

**`generate_response(messages, model, temperature, max_tokens, stop)`** ğŸ’¬
- **æ ¸å¿ƒæ–¹æ³•**ï¼šç”ŸæˆLLMå“åº”
- æ”¯æŒå¤šè½®å¯¹è¯å’Œå‚æ•°é…ç½®
- å¤„ç†APIé”™è¯¯å’Œå¼‚å¸¸æƒ…å†µ

```python
def generate_response(self, messages: list[dict],
                      model: str = "deepseek-chat",
                      temperature: float = 0.0,
                      max_tokens: int = 4096,
                      stop: list[str] | None = None) -> str:
    if stop is None:
        stop = ["<|eot_id|>", "<|end_of_text|>"]
    try:
        response = self.client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            stop=stop,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"API Error: {str(e)}"
```

## ğŸ“ æ–‡æœ¬å¤„ç†å·¥å…·

### ä»£ç å¤„ç†å‡½æ•° (`text_utils.py`)

**`extract_code(text)`** ğŸ”
- **å…³é”®å‡½æ•°**ï¼šä»LLMå“åº”ä¸­æå–Pythonä»£ç å—
- æ”¯æŒå¤šç§ä»£ç å—æ ¼å¼
- éªŒè¯ä»£ç è¯­æ³•æ­£ç¡®æ€§

```python
def extract_code(text: str) -> str:
    parsed_codes: list[str] = []
    matches = re.findall(r"```(python)?\n*(.*?)\n*```", text, re.DOTALL)
    for match in matches:
        code_block = match[1]
        parsed_codes.append(code_block)
    if len(parsed_codes) == 0:
        matches = re.findall(r"^(```(python)?)?\n?(.*?)\n?(```)?$", text, re.DOTALL)
        if matches:
            code_block = matches[0][2]
            parsed_codes.append(code_block)
    valid_code_blocks = [c for c in parsed_codes if is_valid_python_script(c)]
    return "\n\n".join(valid_code_blocks)
```

**`extract_text_up_to_code(s)`**
- æå–ä»£ç å—ä¹‹å‰çš„æ–‡æœ¬å†…å®¹ï¼ˆé€šå¸¸æ˜¯è®¡åˆ’æè¿°ï¼‰

```python
def extract_text_up_to_code(s: str) -> str:
    if "```" not in s:
        return ""
    return s[: s.find("```")].strip()
```

**`wrap_code(code, lang="python")`**
- å°†ä»£ç åŒ…è£…æˆMarkdownæ ¼å¼çš„ä»£ç å—

```python
def wrap_code(code: str, lang: str = "python") -> str:
    return f"```{lang}\n{code}\n```"
```

**`is_valid_python_script(script)`**
- éªŒè¯Pythonä»£ç çš„è¯­æ³•æ­£ç¡®æ€§

```python
def is_valid_python_script(script: str) -> bool:
    try:
        compile(script, "<string>", "exec")
        return True
    except SyntaxError:
        return False
```

### JSONå¤„ç†å‡½æ•° (`text_utils.py`)

**`extract_jsons(text)`**
- ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰æœ‰æ•ˆçš„JSONå¯¹è±¡
- ç”¨äºè§£æLLMè¿”å›çš„ç»“æ„åŒ–è¯„ä¼°ç»“æœ

```python
def extract_jsons(text: str) -> list[dict]:
    json_objects = []
    matches = re.findall(r"\{.*?\}", text, re.DOTALL)
    for match in matches:
        try:
            json_obj = json.loads(match)
            json_objects.append(json_obj)
        except json.JSONDecodeError:
            pass
    return json_objects
```

### æ–‡æœ¬å·¥å…·å‡½æ•° (`text_utils.py`)

**`trim_long_string(string, threshold=5100, k=2500)`**
- æˆªæ–­è¿‡é•¿çš„å­—ç¬¦ä¸²ï¼Œä¿ç•™é¦–å°¾éƒ¨åˆ†
- é˜²æ­¢è¾“å‡ºä¿¡æ¯è¿‡é•¿å½±å“æ€§èƒ½

```python
def trim_long_string(string: str, threshold: int = 5100, k: int = 2500) -> str:
    if len(string) > threshold:
        first_k_chars = string[:k]
        last_k_chars = string[-k:]
        truncated_len = len(string) - 2 * k
        return f"{first_k_chars}\n ... [{truncated_len} characters truncated] ... \n{last_k_chars}"
    return string
```

## ğŸ› ï¸ é€šç”¨å·¥å…·å‡½æ•°

### æ•°æ®å¤„ç†å‡½æ•° (`utils.py`)

**`data_preview_generate(base_path)`** ğŸ“Š
- **é‡è¦å‡½æ•°**ï¼šç”Ÿæˆæ•°æ®é›†é¢„è§ˆä¿¡æ¯
- ä¸ºä»£ç†æä¾›æ•°æ®ä¸Šä¸‹æ–‡ï¼ŒæŒ‡å¯¼ä»£ç ç”Ÿæˆ

```python
def data_preview_generate(base_path):
    result = []
    files = [p for p in Path(base_path).iterdir()]
    for f in sorted(files):
        result.append(preview_csv(f))
    return "\n\n".join(result)
```

**`preview_csv(p)`**
- ç”Ÿæˆå•ä¸ªCSVæ–‡ä»¶çš„è¯¦ç»†é¢„è§ˆ
- åŒ…å«æ•°æ®å½¢çŠ¶ã€åˆ—ä¿¡æ¯ã€ç»Ÿè®¡æ‘˜è¦ç­‰

```python
def preview_csv(p: Path) -> str:
    df = pd.read_csv(p)
    out: list[str] = []
    out.append(f"--- Data Preview for {str(p)} ---")
    out.append(f"Shape: {df.shape[0]} rows and {df.shape[1]} columns.")
    out.append("-" * 20)
    buffer = io.StringIO()
    df.info(buf=buffer, verbose=False)
    info_str = buffer.getvalue()
    out.append("Column Overview (Name, Non-Null Count, Dtype):")
    out.append(info_str)
    out.append("-" * 20)
    out.append("Data Head:")
    out.append(df.head().to_string())
    out.append("-" * 20)
    numeric_df = df.select_dtypes(include='number')
    if not numeric_df.empty:
        out.append("Numerical Columns Statistics:")
        out.append(numeric_df.describe().to_string())
        out.append("-" * 20)
    if 'sample_submission.csv' in str(p):
        out.append("Submission File Format:")
        out.append("The goal is to predict the 'positive' column for each 'id'.")
    out.append(f"--- End of Preview for {str(p)} ---")
    return "\n\n".join(out)
```

### ç»“æœä¿å­˜å‡½æ•° (`utils.py`)

**`save_run(cfg, journal)`**
- ä¿å­˜æœç´¢è¿‡ç¨‹çš„æœ€ä½³è§£å†³æ–¹æ¡ˆ
- ç”Ÿæˆ `best_solution.py` å’Œå¤šä¸ª `good_solution_*.py` æ–‡ä»¶

```python
def save_run(cfg, journal):
    best_node = journal.get_best_node(only_good=False)
    if best_node is not None:
        with open("best_solution.py", "w", encoding="utf-8") as f:
            f.write(best_node.code)

    good_nodes = journal.get_good_nodes()
    for i, node in enumerate(good_nodes):
        filename = f"good_solution_{i}.py"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(node.code)
```

## ğŸ”§ é…ç½®ç³»ç»Ÿ

### Configç±» (`config.py`)
**é…ç½®ç®¡ç†**: é€’å½’åœ°å°†å­—å…¸è½¬æ¢ä¸ºå¯¹è±¡å±æ€§è®¿é—®

```python
class Config:
    def __init__(self, dictionary):
        for key, value in dictionary.items():
            if isinstance(value, dict):
                value = Config(value)
            setattr(self, key, value)
```

**`__init__(dictionary)`**
- æ”¯æŒåµŒå¥—å­—å…¸çš„å±æ€§åŒ–è®¿é—®

### é…ç½®å‡½æ•° (`config.py`)

**`set_seed(seed=531)`**
- è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å®éªŒå¯é‡ç°

```python
def set_seed(seed=531):
    random.seed(seed)
    np.random.seed(seed)
```

## ğŸš€ ç¨‹åºå…¥å£

### mainå‡½æ•° (`main.py`)
**ä¸»ç¨‹åº**: åè°ƒæ‰€æœ‰ç»„ä»¶ï¼Œæ‰§è¡Œå®Œæ•´çš„ä»£ç†æœç´¢æµç¨‹

```python
def main():
    def exec_callback(*args, **kwargs):
        res = interpreter.run(*args, **kwargs)
        return res

    journal = Journal()
    
    # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
    
    llm = LLMClient(
        api_key=api_key,
        base_url="https://api.deepseek.com/v1",
    )
    agent = Agent(cfg=cfg, journal=journal, llm=llm)

    interpreter = Interpreter()

    global_step = len(journal)
    while global_step < cfg.agent.steps:
        agent.step(exec_callback=exec_callback)
        save_run(cfg, journal)
        global_step = len(journal)

    interpreter.cleanup_session()
```

æ‰§è¡Œæµç¨‹ï¼š
1. åŠ è½½ç¯å¢ƒå˜é‡å’ŒAPIå¯†é’¥
2. åˆå§‹åŒ–Journalã€LLMClientã€Agentå’ŒInterpreter
3. æ‰§è¡ŒæŒ‡å®šæ­¥æ•°çš„ä»£ç†æœç´¢
4. ä¿å­˜æœ€ç»ˆç»“æœ

## ğŸ“‹ åŠŸèƒ½æµç¨‹æ€»ç»“

### å®Œæ•´æ‰§è¡Œæµç¨‹
1. **åˆå§‹åŒ–** â†’ åˆ›å»ºä»£ç†ã€çŠ¶æ€ç®¡ç†å™¨ã€æ‰§è¡Œå¼•æ“
2. **æ•°æ®é¢„è§ˆ** â†’ ç”Ÿæˆæ•°æ®é›†ä¸Šä¸‹æ–‡ä¿¡æ¯
3. **æœç´¢å¾ªç¯** â†’ é‡å¤æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
   - æœç´¢ç­–ç•¥å†³ç­–
   - ä»£ç ç”Ÿæˆï¼ˆè‰ç¨¿/è°ƒè¯•/æ”¹è¿›ï¼‰
   - ä»£ç æ‰§è¡Œ
   - ç»“æœè¯„ä¼°
   - çŠ¶æ€æ›´æ–°
4. **ç»“æœä¿å­˜** â†’ è¾“å‡ºæœ€ä½³è§£å†³æ–¹æ¡ˆ

### å…³é”®è®¾è®¡æ¨¡å¼
- **ç­–ç•¥æ¨¡å¼**: æœç´¢ç­–ç•¥çš„åŠ¨æ€é€‰æ‹©
- **çŠ¶æ€æ¨¡å¼**: èŠ‚ç‚¹é˜¶æ®µçš„ç®¡ç†
- **è§‚å¯Ÿè€…æ¨¡å¼**: æ‰§è¡Œç»“æœçš„å¤„ç†
- **å·¥å‚æ¨¡å¼**: èŠ‚ç‚¹çš„åˆ›å»ºå’Œç®¡ç†

è¿™ä¸ªæ¶æ„å®ç°äº†AIDEè®ºæ–‡ä¸­æå‡ºçš„AIé©±åŠ¨ä»£ç ç©ºé—´æ¢ç´¢çš„æ ¸å¿ƒç†å¿µï¼Œé€šè¿‡æ ‘æœç´¢å’Œæ™ºèƒ½é‡ç”¨å®ç°äº†è‡ªåŠ¨åŒ–çš„æœºå™¨å­¦ä¹ å·¥ç¨‹ã€‚
